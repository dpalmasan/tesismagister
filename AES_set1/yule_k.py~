import string
from nltk.corpus import stopwords
import enchant
import codecs
import nltk
from collections import Counter
from textstat.textstat import textstat
import math

stoplist = stopwords.words('english')
d = enchant.Dict("en_US")

# Lee un ensayo y retorna el texto puro
def read_essay(filename):
	with codecs.open(filename, 'r', "utf-8") as file:
		return file.read()

# Funcion auxiliar para aplicar translate a strings unicode
def translate_non_alphanumerics(to_translate, translate_to=u'_'):
	not_letters_or_digits = u'!"#%()*+,-./:;<=>?[\]^_`{|}~'
	translate_table = dict((ord(char), translate_to) for char in not_letters_or_digits)
	return to_translate.translate(translate_table)

# Reemplaza puntuacion por espacios
def strip_punctuation(text):
	return translate_non_alphanumerics(text, translate_to = u' ')

def get_yules(tokens):
	N = len(tokens)
	tmp1 = Counter(tokens)
	tmp2 = Counter(tmp1.values())
	sum_term = sum([r**2 * tmp2[r] for r in tmp2.keys()])/float(N*N)
	sum_term -= 1/float(N)
	return 10000 * sum_term
	

def hapax_legomena(tokens):
	type_tokens = set(tokens)
	hapax = 0
	for token in type_tokens:
		if tokens.count(token) == 1:
			hapax += 1
	return hapax


header = "yule_k\n"
with codecs.open("yule_k.csv", "w", "utf-8") as output:
    output.write(header)

for id in range(1, 1785):
    essay = read_essay("essays/" + str(id) + ".txt")
    essay_lower = essay.lower()
    words = strip_punctuation(essay_lower).split()
    words = [word for word in words if word[0] != '@']
    yule_k = get_yules(words)

    with codecs.open("yule_k.csv", "a", "utf-8") as output:
        output.write(str(yule_k) + "\n")

